{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b36e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07803131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb31bab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import array_to_img,img_to_array,load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5188932b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     15\u001b[0m                 \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mcreate_training_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m, in \u001b[0;36mcreate_training_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_training_data\u001b[39m():\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m class_num, category \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(CATEGORIES):\n\u001b[0;32m----> 8\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(DATADIR, category)\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m image_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(path):\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "DATADIR = \"./Original\"\n",
    "CATEGORIES = [\"class1\", \"class2\"]\n",
    "IMG_SIZE_x = 70\n",
    "IMG_SIZE_y = 19\n",
    "training_data = []\n",
    "def create_training_data():\n",
    "    for class_num, category in enumerate(CATEGORIES):\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        for image_name in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, image_name), cv2.IMREAD_GRAYSCALE)  # 画像読み込み\n",
    "                img_resize_array = cv2.resize(img_array, (IMG_SIZE_x, IMG_SIZE_y))  # 画像のリサイズ\n",
    "                training_data.append([img_resize_array, class_num])  # 画像データ、ラベル情報を追加\n",
    "            except Exception as e:\n",
    "                pass\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8e5b5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習データのラベル： 1\n",
      "学習データのラベル： 0\n",
      "学習データのラベル： 1\n",
      "学習データのラベル： 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAExCAYAAADhgaFsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAV2klEQVR4nO3df2zU9R3H8dcV5Cg/amnvMCCgbcfWAhE3/BUSWhdQEwMphGAgHY1WZWEVh4mZZkoaEgWRzMRg2B+Q1MYQUwuCEYeDuHaiaVI6iNkkrmQOmAdVWssPOSis/ewP43d37R1c6bV35/v5SEjed9/P9/v93Pd6n774fL/3rc855wQAAMzKSnUHAABAahEGAAAwjjAAAIBxhAEAAIwjDAAAYBxhAAAA4wgDAAAYRxgAAMA4wgAAAMYRBjJIU1OTfD6fmpqaUt0VABmCcQOJIAwgYZ2dndq8ebNKS0sVDAaVm5ur++67T/X19anuGoA0Vl9fr1/96leaPn26fD6f7r///lR3CX0QBpCw5uZmvfDCC8rLy9OLL76ol19+WWPGjNHy5ctVU1OT6u4BSFN//OMf9d5772nq1KmaMGFCqruDGEamugPIHDNnztSxY8d02223ec/95je/0YIFC7Rp0yb97ne/09ixY1PYQwDp6K233tKtt96qrKwszZo1K9XdQQzMDKSZUCikxx9/XJMnT5bf71dBQYFWr16tK1euxGx/8OBBLVu2TNOmTZPf79fUqVP1zDPP6NKlS1Ht2tvb9dhjj2nKlCny+/2aNGmSysvLdfz4ca9Na2urHnroIQUCAWVnZ6ugoEBVVVXe8oKCgqggIEk+n0+LFy9Wd3e3vvzyy+QdCAAJS+dxQ5KmTp2qrCx+3aQzZgbSyKlTp3TPPffo7NmzWrVqlYqLixUKhbRz506Fw+GY6zQ0NCgcDmv16tXKz89XS0uLtmzZoq+++koNDQ1eu6VLl+rzzz/XmjVrdPvtt+ubb77RgQMHdPLkSe/xgw8+qGAwqOeff165ubk6fvy43n333ev2u729XZIUCASScyAAJCxTxw2kGYe0UVlZ6bKystyhQ4f6Levt7XWNjY1OkmtsbPSeD4fD/dpu3LjR+Xw+d+LECeecc11dXU6S27x5c9x9796920mKue9r6ezsdBMnTnTz5s0b0HoAkiPTxo2ZM2e6srKyhNtjeDBvkyZ6e3u1Z88eLVq0SHfddVe/5T6fL+Z62dnZXn3x4kV1dHRo7ty5cs7pyJEjXptRo0apqalJXV1dMbeTm5srSdq7d6+uXr2acJ8rKip09uxZbdmyJaF1ACRPJo4bSE+EgTRx5swZnT9/fsAX15w8eVKPPvqo8vLyNG7cOAWDQZWVlUmSzp07J0ny+/3atGmT9u3bp1tuuUWlpaV69dVXvel9SSorK9PSpUu1fv16BQIBlZeXq7a2Vt3d3XH3vWbNGn344Yfavn27Zs+efQOvGsBgZOK4gfREGMhgPT09euCBB/TBBx/oueee0549e3TgwAG9+eabkr7/X8MP1q5dq7a2Nm3cuFGjR4/WunXrVFJS4v0vwOfzaefOnWpubtZTTz2lUCikqqoqzZkzR999912/fa9fv15bt27VK6+8opUrVw7L6wUweKkcN5DGUn2eAt/r6elxOTk5rry8PG6bvuf+jhw54iS5urq6qHb79+93klxtbW3cbbW1tbkxY8a4ioqKuG127NjhJLlt27ZFPf/GG284SW7t2rXXfV0Ahk4mjRs/4JqB9MTMQJrIysrS4sWL9f7776u1tbXfcudcv+dGjBjRb5lzTq+//npUu3A4rMuXL0c9V1RUpPHjx3vTeV1dXf32ceedd0pS1JRffX29nn76aVVUVOi1114bwCsEkGyZMm4g/fHVwjSyYcMG7d+/X2VlZVq1apVKSkp0+vRpNTQ06JNPPunXvri4WEVFRXr22WcVCoWUk5OjXbt29bvYp62tTfPnz9cjjzyiGTNmaOTIkdq9e7e+/vprLV++XJJUV1enrVu3asmSJSoqKtKFCxe0bds25eTk6OGHH5YktbS0qLKyUvn5+Zo/f7527NgRtZ+5c+eqsLBwiI4OgFjSfdyQpI8//lgff/yxpO+vc7h48aJeeuklSVJpaalKS0uH6vAgUamblEAsJ06ccJWVlS4YDDq/3+8KCwtddXW16+7ujvkVoaNHj7oFCxa4cePGuUAg4J588kn32WefRU33dXR0uOrqaldcXOzGjh3rbr75Znfvvfe6d955x9vO4cOH3YoVK9y0adOc3+93EydOdAsXLnStra1em9raWicp7r9rTS8CGDrpPG4451xNTU3ccaOmpmYYjhCux+dcjHkkAABgBtcMAABgHGEAAADjCAMAABhHGAAAwDjCAAAAxhEGAAAwjjAAAIBxCd+BMN6fwgQwfDLxtiCMHUDqXW/sYGYAAADjCAMAABhHGAAAwDjCAAAAxhEGAAAwjjAAAIBxhAEAAIwjDAAAYBxhAAAA4wgDAAAYRxgAAMA4wgAAAMYRBgAAMI4wAACAcYQBAACMIwwAAGAcYQAAAOMIAwAAGDcy0YYtLS1D1on6+nqv/sMf/jDgfe7bt8+rQ6FQzDZPPPFEQtvavn173GVlZWVe/de//tWrb731Vq/u7e316itXrkStv2TJkoT6kAlqa2ujHvf09Hj1ihUrvPrtt9+Ou41JkyZ5dVbW/3Np5HsYecynT59+Y51NI3V1dV599epVr162bFlUu4aGBq9etGjR0HcMQ8o559U+ny+FPQFiY2YAAADjCAMAABiX8GmCu+++e8g60dzcPKh9/vOf//TqyOm4G9nWn/70p7jLZs6c6dXHjh3z6sLCQq+OPE1w+fLlG+pDJvjzn/8c9TjyNMEvfvELr448ndJXQUGBV0eeJoh8DyOP+ezZs2+ss2nko48+8uru7m6vjjxmkvTpp5969R133DH0HQNgGjMDAAAYRxgAAMA4n4s3r97HrFmzhqwTnZ2dXt3e3u7VkVPE13Lu3Dmv7nsF/w+CwWBC2zpz5kzcZePHj/fqCxcuePWoUaO8OvJw9j20EyZMSKgPmeBaxykQCHh1R0dH3HY33XSTV0deYR35HkYe89GjRw+4n+km8nhE/nzk5eVFtfv222+9OvLn5osvvhjC3g0Nrp7n2wRIvev9qmdmAAAA4wgDAAAYl/BpAqa2gNRL8OOaVhg7OE2A1OM0AQAAuCbCAAAAxhEGAAAwLuE7EAIAgMwxkGuMmBkAAMA4wgAAAMZxmgAAhlGmfM0wE7/GihvHzAAAAMYRBgAAMI47EAIZJBOnbhk7oi1cuDDVXRiwvXv3DnidTHydkW7kNSf6+RyuzwTfJgAAAAkjDAAAYBynCYAMwmmCH690mFa/kanxwUr16x6q13ytzyqnCQAAQNohDAAAYBxhAAAA47hmAMggXDNgUzLPq6fiugCL+n5WU/E54JoBAACQMMIAAADGcZoAyCCcJgCQKE4TAACAhBEGAAAwjjAAAIBxhAEAAIwjDAAAYNzIVHcAAICBGOxNmLjxUn/MDAAAYBxhAAAA4wgDAAAYxzUDAIZUJt41EbCGmQEAAIwjDAAAYFzCpwmY6gMA4MeJmQEAAIwjDAAAYBxhAAAA4wgDAAAYRxgAAMA4wgAAAMYRBgAAMI4wAACAcYQBAACMIwwAAGAcYQAAAOMIAwAAGEcYAADAOMIAAADGEQYAADCOMAAAgHGEAQAAjCMMAABgHGEAAADjCAMAABhHGAAAwDjCAAAAxhEGAAAwjjAAAIBxhAEAAIwjDAAAYBxhAAAA4wgDAAAYRxgAAMA4wgAAAMYRBgAAMI4wAACAcYQBAACMIwwAAGAcYQAAAOMIAwAAGEcYAADAOMIAAADGEQYAADCOMAAAgHGEAQAAjCMMAABgHGEAAADjCAMAABhHGAAAwDjCAAAAxhEGAAAwjjAAAIBxhAEAAIwjDAAAYBxhAAAA4wgDAAAYRxgAAMA4wgAAAMYRBgAAMI4wAACAcYQBAACMIwwAAGAcYQAAAOMIAwAAGEcYAADAOMIAAADGEQYAADCOMAAAgHGEAQAAjCMMAABgHGEAAADjCAMAABhHGAAAwDjCAAAAxhEGAAAwjjAAAIBxhAEAAIwjDAAAYBxhAAAA4wgDAAAYRxgAAMA4wgAAAMYRBgAAMI4wAACAcYQBAACMIwwAAGAcYQAAAOMIAwAAGEcYAADAOMIAAADGEQYAADCOMAAAgHGEAQAAjCMMAABgHGEAAADjCAMAABhHGAAAwDjCAAAAxhEGAAAwjjAAAIBxhAEAAIwjDAAAYBxhAAAA4wgDAAAYRxgAAMA4wgAAAMYRBgAAMI4wAACAcYQBAACMIwwAAGAcYQAAAOMIAwAAGEcYAADAOMIAAADGEQYAADCOMAAAgHGEAQAAjCMMAABgHGEAAADjCAMAABhHGAAAwDjCAAAAxhEGMkhTU5N8Pp+amppS3RUAGYJxA4kgDCBhnZ2d2rx5s0pLSxUMBpWbm6v77rtP9fX1qe4agDTFuJEZCANIWHNzs1544QXl5eXpxRdf1Msvv6wxY8Zo+fLlqqmpSXX3AKQhxo3M4HPOuVR3AolpamrSL3/5SzU2Nur+++8f9v3/+9//VlZWlm677TbvOeecFixYoE8//VSdnZ0aO3bssPcLQHyMG0gEMwNpJhQK6fHHH9fkyZPl9/tVUFCg1atX68qVKzHbHzx4UMuWLdO0adPk9/s1depUPfPMM7p06VJUu/b2dj322GOaMmWK/H6/Jk2apPLych0/ftxr09raqoceekiBQEDZ2dkqKChQVVWVt7ygoCDqAy1JPp9PixcvVnd3t7788svkHQgACWPcwGCNTHUH8H+nTp3SPffco7Nnz2rVqlUqLi5WKBTSzp07FQ6HY67T0NCgcDis1atXKz8/Xy0tLdqyZYu++uorNTQ0eO2WLl2qzz//XGvWrNHtt9+ub775RgcOHNDJkye9xw8++KCCwaCef/555ebm6vjx43r33Xev2+/29nZJUiAQSM6BAJAwxg0khUPaqKysdFlZWe7QoUP9lvX29rrGxkYnyTU2NnrPh8Phfm03btzofD6fO3HihHPOua6uLifJbd68Oe6+d+/e7STF3Pe1dHZ2uokTJ7p58+YNaD0AycG4gWTgNEGa6O3t1Z49e7Ro0SLddddd/Zb7fL6Y62VnZ3v1xYsX1dHRoblz58o5pyNHjnhtRo0apaamJnV1dcXcTm5uriRp7969unr1asJ9rqio0NmzZ7Vly5aE1gGQPIwbSBbCQJo4c+aMzp8/r1mzZg1ovZMnT+rRRx9VXl6exo0bp2AwqLKyMknSuXPnJEl+v1+bNm3Svn37dMstt6i0tFSvvvqqN00nSWVlZVq6dKnWr1+vQCCg8vJy1dbWqru7O+6+16xZow8//FDbt2/X7Nmzb+BVAxgMxg0kC2Egg/X09OiBBx7QBx98oOeee0579uzRgQMH9Oabb0r6PoH/YO3atWpra9PGjRs1evRorVu3TiUlJd7/Anw+n3bu3Knm5mY99dRTCoVCqqqq0pw5c/Tdd9/12/f69eu1detWvfLKK1q5cuWwvF4Ag8e4gZhSfZ4C3+vp6XE5OTmuvLw8bpu+5/6OHDniJLm6urqodvv373eSXG1tbdxttbW1uTFjxriKioq4bXbs2OEkuW3btkU9/8YbbzhJbu3atdd9XQCGDuMGkoWZgTSRlZWlxYsX6/3331dra2u/5S7G7SBGjBjRb5lzTq+//npUu3A4rMuXL0c9V1RUpPHjx3vTeV1dXf32ceedd0pS1JRffX29nn76aVVUVOi1114bwCsEkGyMG0gWvlqYRjZs2KD9+/errKxMq1atUklJiU6fPq2GhgZ98skn/doXFxerqKhIzz77rEKhkHJycrRr165+F/u0tbVp/vz5euSRRzRjxgyNHDlSu3fv1tdff63ly5dLkurq6rR161YtWbJERUVFunDhgrZt26acnBw9/PDDkqSWlhZVVlYqPz9f8+fP144dO6L2M3fuXBUWFg7R0QEQC+MGkiJ1kxKI5cSJE66ystIFg0Hn9/tdYWGhq66udt3d3TG/InT06FG3YMECN27cOBcIBNyTTz7pPvvss6jpvo6ODlddXe2Ki4vd2LFj3c033+zuvfde984773jbOXz4sFuxYoWbNm2a8/v9buLEiW7hwoWutbXVa1NbW+skxf13relFAEOHcQODxe2IAQAwjmsGAAAwjjAAAIBxhAEAAIwjDAAAYBxhAAAA4wgDAAAYRxgAAMC4hO9AGO9PYQIYPpl4WxDGDiD1rjd2MDMAAIBxhAEAAIwjDAAAYBxhAAAA4wgDAAAYRxgAAMA4wgAAAMYRBgAAMI4wAACAcYQBAACMIwwAAGBcwn+bAAAApN5Pf/rTmPVgMDMAAIBxhAEAAIzjNAEAAEk2YcKEaz4ejJUrV3p1VVVVUrbJzAAAAMYRBgAAMI4wAACAcQlfM9DS0jKU/fA0NjZ69b/+9a+E1ikqKvLq8+fPe/WZM2firjNq1CivrqysHEgXMQDd3d1e/dZbbw14/fLycq9+7733opZFvoezZs3y6sOHDye07WAw6NU5OTle/Z///Cfmdvtu+4knnkhoPwDs+e1vfxv1uKamJmnbfumll7y6sLAwoXUuX758zeXMDAAAYBxhAAAA4xI+TXD33XcPZT88kVO0ly5dSmidn/zkJ17d2dnp1TfddFPcdbKzs716uF6bRZHv4UcffTTg9e+44w6vPnToUNSyyPfwZz/7mVe3t7cntO3Jkyd7dX5+fsw2kdvtu21+boDMV11dHbMerF27dkU9/vnPf560bZ8+fdqrI0/FDgYzAwAAGEcYAADAOJ9zziXSsO9V1UPlwoULXn29qx9/MHr0aK/+73//G7Puy+fzeXUgEBhIFzEAkT9eHR0dA14/8q5dXV1dUcsi38PIUwbhcDihbY8cOTJmHTntFrndvtuO/DbCcPnHP/4x7PscrMj3CRgukaePlyxZErUscpo98lTg0aNHk7b/v//971GPU/3Zvd6vemYGAAAwjjAAAIBxCZ8mYKoPSL0EP65pJfIGKcn2l7/8Jebz8+bN8+qDBw/GXXatbxylkw0bNnj173//+yHbz7p167z617/+tVdPmTIlafv429/+FnfZnDlzkrafSH2n/7/99luvvnLlildH3vTux4bTBAAA4JoIAwAAGEcYAADAuITvQAgAN2LGjBlDtu2+X9/6QUlJiVd/8cUXcZdF/rGrdDZixAivHsrjGamgoMCrp0+fnrTtnjp1Ku6yZL62Y8eOefXbb7+dtO3+WDEzAACAcYQBAACM46uFQAbJxK8WMnYAqcdXCwEAwDURBgAAMI4wAACAcYQBAACMIwwAAGAcYQAAAOMIAwAAGEcYAADAOMIAAADGEQYAADCOMAAAgHGEAQAAjCMMAABgHGEAAADjCAMAABhHGAAAwDjCAAAAxhEGAAAwjjAAAIBxhAEAAIwjDAAAYBxhAAAA4wgDAAAYRxgAAMA4wgAAAMb5nHMu1Z0AAACpw8wAAADGEQYAADCOMAAAgHGEAQAAjCMMAABgHGEAAADjCAMAABhHGAAAwDjCAAAAxv0PbdPdVjO/5t4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.shuffle(training_data)  # データをシャッフル\n",
    "X_train = []  # 画像データ\n",
    "y_train = []  # ラベル情報\n",
    "# データセット作成\n",
    "for feature, label in training_data:\n",
    "    X_train.append(feature)\n",
    "    y_train.append(label)\n",
    "# numpy配列に変換\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "# データセットの確認\n",
    "for i in range(0, 4):\n",
    "    print(\"学習データのラベル：\", y_train[i])\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.title(label = 'class1' if y_train[i] == 0 else 'class2')\n",
    "    plt.imshow(X_train[i], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71de4fc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target_file \u001b[38;5;129;01min\u001b[39;00m i:\n\u001b[1;32m     10\u001b[0m     image\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Original/class2/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mtarget_file)\n\u001b[0;32m---> 11\u001b[0m     temp_img\u001b[38;5;241m=\u001b[39m\u001b[43mload_img\u001b[49m(image)\n\u001b[1;32m     12\u001b[0m     temp_img_array\u001b[38;5;241m=\u001b[39mimg_to_array(temp_img)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(temp_img_array\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_img' is not defined"
     ]
    }
   ],
   "source": [
    "X_train=[]\n",
    "Y_train=[]\n",
    "\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "\n",
    "i=os.listdir(\"./Original/class2\")\n",
    "n=0\n",
    "for target_file in i:\n",
    "    image=(\"./Original/class2/\"+target_file)\n",
    "    temp_img=load_img(image)\n",
    "    temp_img_array=img_to_array(temp_img)\n",
    "    print(temp_img_array.shape)\n",
    "    X_train.append(temp_img_array)\n",
    "    n=n+1\n",
    "\n",
    "np.savez(\"./gan/gan.npz\",x_train=X_train,y_train=Y_train,x_test=X_test,y_test=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb16384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 128\n",
    "        self.img_cols = 128\n",
    "        self.channels = 1 \n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "\n",
    "        f=np.load(\"/home/gan/gan.npz\")\n",
    "        X_train=f[\"x_train\"]\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Generate a batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Train the generator (to have the discriminator label samples as valid)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"gan/%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gan = GAN()\n",
    "    gan.train(epochs=30000, batch_size=32, sample_interval=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for TensorFlow GPU access\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "# See TensorFlow version\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2f6468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
